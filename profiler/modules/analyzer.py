# -*- coding: utf-8 -*-
import json
import os
import asyncio
import google.generativeai as genai
import sys
import time

sys.path.append("..")
import config
from modules import reporter

INPUT_FILE = config.PROCESSED_DATA_DIR / "clean_data.json"

# --- 1. [1ì°¨ ë¶„ì„] ì¡°ê° ë¶„ì„ í”„ë¡¬í”„íŠ¸ ---
PARTIAL_ANALYSIS_PROMPT = """
ë‹¹ì‹ ì€ ë°ì´í„° ì‹¬ë¦¬í•™ìì´ì ì •ì¹˜ ì‚¬íšŒí•™ í”„ë¡œíŒŒì¼ëŸ¬ì…ë‹ˆë‹¤.
ì•„ë˜ í…ìŠ¤íŠ¸ëŠ” íŠ¹ì • ë””ìŠ¤ì½”ë“œ ìœ ì €ì˜ ëŒ€í™” ë‚´ìš©ì…ë‹ˆë‹¤.
ì´ í…ìŠ¤íŠ¸ì—ì„œ ë“œëŸ¬ë‚˜ëŠ” ìœ ì €ì˜ **ì„±í–¥ì  ë‹¨ì„œ(Cues)**ë¥¼ ì°¾ì•„ ê°„ê²°í•˜ê²Œ ë©”ëª¨í•˜ì„¸ìš”.

[ì¤‘ì  íƒìƒ‰ í•­ëª©]
1. **ì •ì¹˜/ì‚¬íšŒì  ì„±í–¥ ë‹¨ì„œ**: ê¶Œìœ„/ê·œë²” íƒœë„, ê²½ì œ/ì‚¬íšŒ ê´€ì , ì •ì¹˜ì  ë°ˆ ë§¥ë½.
2. **ë¬¸í™”/ê²Œì„ ì†Œë¹„ íŒ¨í„´**: ì„ í˜¸ ì¥ë¥´, í”Œë ˆì´ ìŠ¤íƒ€ì¼, ì„œë¸Œì»¬ì²˜ ëª°ì…ë„.
3. **í™”ë²• ë° ì„±ê²©**: ë…¼ë¦¬/ê°ì •, ê³µê²©ì„±, ìœ ë¨¸ ì½”ë“œ.

[ëŒ€í™” ë°ì´í„°]
{chunk_text}

[ì¶œë ¥ í˜•ì‹]
- í•µì‹¬ íŠ¹ì§•ë§Œ ë¶ˆì¡°(Bullet point)ë¡œ ë‚˜ì—´.
"""

# --- 2. [2ì°¨ ë¶„ì„] ì¢…í•© ë¦¬í¬íŠ¸ í”„ë¡¬í”„íŠ¸ (ìˆ˜ì • ì—†ìŒ, ë™ì¼) ---
FINAL_SYNTHESIS_PROMPT = """
ë‹¹ì‹ ì€ ì—˜ë¦¬íŠ¸ í”„ë¡œíŒŒì¼ëŸ¬ì…ë‹ˆë‹¤. ì•„ë˜ ë‚´ìš©ì€ í•œ ìœ ì €ì˜ 3ë…„ ì¹˜ ëŒ€í™” ë°ì´í„°ë¥¼ ë¶„ì„í•œ 'ê´€ì°° ë…¸íŠ¸'ë“¤ì…ë‹ˆë‹¤.
ì´ ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬, í•´ë‹¹ ìœ ì €ì˜ ì •ì²´ì„±ì„ ê¿°ëš«ëŠ” **[ì‹¬ì¸µ í”„ë¡œíŒŒì¼ë§ ë³´ê³ ì„œ]**ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

[ê´€ì°° ë…¸íŠ¸ ëª¨ìŒ]
{summaries}

---

[ë³´ê³ ì„œ ì‘ì„± ê°€ì´ë“œë¼ì¸ (ì—„ìˆ˜)]

### 1. ğŸ›ï¸ ì‚¬íšŒ/ì •ì¹˜ì  ì„±í–¥ ë° ê°€ì¹˜ê´€ (Political & Social Compass)
*ë‹¨ìˆœí•œ ë³´ìˆ˜/ì§„ë³´ êµ¬ë¶„ì„ ë„˜ì–´, ì‚¬íšŒë¥¼ ë°”ë¼ë³´ëŠ” ê·¼ë³¸ì ì¸ í”„ë ˆì„ì„ ë¶„ì„í•˜ì„¸ìš”.*
- **ì´ë…ì  ìŠ¤í™íŠ¸ëŸ¼**: (ì˜ˆ: ììœ ì§€ìƒì£¼ì˜ì  ìš°íŒŒ, ëƒ‰ì†Œì  í—ˆë¬´ì£¼ì˜, ì‹¤ìš©ì£¼ì˜ì  ì¤‘ë„ ë“±)
- **ì˜ˆìƒ ì§€ì§€ ì‚¬íšŒ ì‹œìŠ¤í…œ**: ì´ ìœ ì €ê°€ ì´ìƒì ì´ë¼ê³  ìƒê°í•˜ê±°ë‚˜, ë¬´ì˜ì‹ì ìœ¼ë¡œ ì§€í–¥í•˜ëŠ” ì²´ì œëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ?
    - *ë³´ê¸°: ê¸°ìˆ ê´€ë£Œì œ(Technocracy), ëŠ¥ë ¥ì£¼ì˜(Meritocracy), ë¬´ì •ë¶€ ìë³¸ì£¼ì˜, ì‚¬íšŒë¯¼ì£¼ì£¼ì˜, ê¶Œìœ„ì£¼ì˜ì  ì§ˆì„œ ë“±*
- **í˜„ì‹¤ ì¸ì‹ íƒœë„**: ì‚¬íšŒ ì´ìŠˆë‚˜ ê¶Œìœ„ì— ëŒ€í•´ ì–´ë–¤ ë°˜ì‘(ë¶„ë…¸, ì¡°ë¡±, ë¬´ê´€ì‹¬, ë¶„ì„)ì„ ë³´ì…ë‹ˆê¹Œ?

### 2. ğŸ® ë¬¸í™”ì  DNA ë° ê²Œì„ ì·¨í–¥ (Cultural Archetype)
- **Core Game Genre**: ì„ í˜¸í•˜ëŠ” ê²Œì„ë“¤ì˜ ê³µí†µëœ ë©”ì»¤ë‹ˆì¦˜ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ? (ì˜ˆ: ê·¹í•œì˜ íš¨ìœ¨ ì¶”êµ¬, ì„œì‚¬ ëª°ì…, í”¼ì§€ì»¬ ê²½ìŸ)
- **ì„œë¸Œì»¬ì²˜ ìˆ˜ìš©ë„**: ì†Œìœ„ 'ì˜¤íƒ€ì¿  ë¬¸í™”'ì— ëŒ€í•œ ì‹¬ë„ì™€ íƒœë„.

### 3. ğŸ’¬ ì„±ê²© ë° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ë§¤íŠ¸ë¦­ìŠ¤ (Personality Matrix)
- **í™”ë²• ë¶„ì„**: í…ìŠ¤íŠ¸ ë’¤ì— ìˆ¨ê²¨ì§„ ê°ì • ìƒíƒœì™€ ì§€ì  ìˆ˜ì¤€.
- **ëŒ€ì¸ ê´€ê³„**: ì§‘ë‹¨ ë‚´ì—ì„œ ì–´ë–¤ ì—­í• (ë¦¬ë”, ì¶”ì¢…ì, ê´‘ëŒ€, ê´€ì°°ì)ì„ ìˆ˜í–‰í•©ë‹ˆê¹Œ?
- **ì¶”ì • MBTI**: (ê°€ì¥ ìœ ë ¥í•œ ìœ í˜• 1ê°œì™€ ê·¸ ë…¼ë¦¬ì  ê·¼ê±°)

### 4. ğŸ”‘ í”„ë¡œíŒŒì¼ë§ ìš”ì•½ (Executive Summary)
- ì´ ì‚¬ëŒì„ ì •ì˜í•˜ëŠ” **í•µì‹¬ í‚¤ì›Œë“œ 3ê°€ì§€** (í˜•ìš©ì‚¬+ëª…ì‚¬ ì¡°í•© ê¶Œì¥)
- **í•œ ì¤„ ì´í‰**: ì´ ìœ ì €ëŠ” ì–´ë–¤ ì‚¬ëŒì…ë‹ˆê¹Œ?

---

[ì‘ì„± í†¤ì•¤ë§¤ë„ˆ]
- **ëƒ‰ì² í•˜ê³  ë¶„ì„ì ì¸ ì „ë¬¸ê°€ì˜ ì–´ì¡°**ë¥¼ ìœ ì§€í•˜ì„¸ìš”.
- ì¶”ìƒì ì¸ í‘œí˜„ë³´ë‹¤ëŠ” **"~ë¼ëŠ” ë°œì–¸ì—ì„œ ~í•œ ì„±í–¥ì´ ë“œëŸ¬ë‚¨"**ê³¼ ê°™ì´ êµ¬ì²´ì ì¸ ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”.
- **í˜•ì‹ì„ ì ˆëŒ€ì ìœ¼ë¡œ ì¤€ìˆ˜**í•˜ì—¬, ëˆ„ê°€ ë´ë„ ë™ì¼í•œ í¬ë§·ì˜ ë³´ê³ ì„œê°€ ë˜ë„ë¡ í•˜ì„¸ìš”.
"""

# ì¤‘ìš” ë³€ê²½: ì²­í¬ í¬ê¸°ë¥¼ 50ë§Œ ìë¡œ ëŒ€í­ ìƒí–¥ (ì•½ 15~20ë§Œ í† í°)
# Gemini 1.5 FlashëŠ” 100ë§Œ í† í°ê¹Œì§€ ê°€ëŠ¥í•˜ë¯€ë¡œ ì¶©ë¶„í•¨.
# ìš”ì²­ íšŸìˆ˜ë¥¼ ì¤„ì´ê¸° ìœ„í•¨.
CHUNK_SIZE = 500000 

async def analyze_chunk(model, text_chunk, index, total):
    """ë°ì´í„° ì¡°ê° 1ì°¨ ë¶„ì„"""
    print(f"     ğŸ§© ë°ì´í„° ì¡°ê° ì‹¬ì¸µ ë¶„ì„ ì¤‘... ({index}/{total})")
    try:
        response = await asyncio.to_thread(
            model.generate_content,
            PARTIAL_ANALYSIS_PROMPT.format(chunk_text=text_chunk)
        )
        return response.text
    except Exception as e:
        # 429 ì—ëŸ¬ê°€ ë‚˜ë©´ ì—¬ê¸°ì„œ ì¡ì•„ì„œ ì²˜ë¦¬ ê°€ëŠ¥ (ì§€ê¸ˆì€ ë¡œê·¸ë§Œ)
        print(f"     âš ï¸ ì¡°ê° {index} ë¶„ì„ ì‹¤íŒ¨: {e}")
        if "429" in str(e):
            print("     â³ ì¿¼í„° ì´ˆê³¼! 60ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
            await asyncio.sleep(60)
            return await analyze_chunk(model, text_chunk, index, total) # ì¬ê·€ ì¬ì‹œë„
        return ""

async def analyze_user(username, user_data):
    full_text = user_data['full_text']
    msg_count = user_data['msg_count']
    
    print(f"   â–¶ [{username}] í”„ë¡œíŒŒì¼ë§ ì‹œì‘... (Data: {msg_count:,} msgs)")

    model = genai.GenerativeModel(config.GEMINI_MODEL)
    
    # 1. í…ìŠ¤íŠ¸ ë¶„í•  (Chunking)
    chunks = [full_text[i:i+CHUNK_SIZE] for i in range(0, len(full_text), CHUNK_SIZE)]
    total_chunks = len(chunks)
    
    partial_results = []
    
    # 2. ë¶„ì„ ì‹¤í–‰
    # ì²­í¬ê°€ 1ê°œë©´ ë°”ë¡œ ìµœì¢… ë¶„ì„ìœ¼ë¡œ ë„˜ê¸°ë©´ í† í°ì€ ì•„ë¼ì§€ë§Œ,
    # "ê´€ì°° ë…¸íŠ¸" -> "ì¢…í•© ë³´ê³ ì„œ"ë¼ëŠ” 2ë‹¨ê³„ ì¶”ë¡  ê³¼ì •ì„ ê±°ì¹˜ëŠ” ê²ƒì´ í€„ë¦¬í‹°ê°€ í›¨ì”¬ ì¢‹ìœ¼ë¯€ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
    # ë‹¨, ì²­í¬ ì‚¬ì´ì¦ˆë¥¼ í‚¤ì› ìœ¼ë¯€ë¡œ ìš”ì²­ íšŸìˆ˜ëŠ” íšê¸°ì ìœ¼ë¡œ ì¤„ì–´ë“­ë‹ˆë‹¤.
    
    print(f"     ğŸ“¦ ë°ì´í„° ì²˜ë¦¬: {total_chunks}íšŒ ìš”ì²­ìœ¼ë¡œ ìµœì í™”ë¨.")
    
    for i, chunk in enumerate(chunks):
        result = await analyze_chunk(model, chunk, i+1, total_chunks)
        if result:
            partial_results.append(result)
        
        # ìš”ì²­ ê°„ ì¿¨íƒ€ì„ (ì•ˆì „í•˜ê²Œ 5ì´ˆ)
        if i < total_chunks - 1:
            await asyncio.sleep(5)

    # 3. ì¢…í•© ë¶„ì„ (Synthesis)
    if not partial_results:
        return "ë¶„ì„ ì‹¤íŒ¨: ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ëª¨ë“  ìš”ì²­ì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤."

    print(f"     ğŸ”„ ìµœì¢… ë¦¬í¬íŠ¸ ì‘ì„± ì¤‘...")
    combined_notes = "\n\n".join(partial_results)
    
    final_prompt = FINAL_SYNTHESIS_PROMPT.format(summaries=combined_notes)
    
    try:
        final_response = await asyncio.to_thread(
            model.generate_content,
            final_prompt
        )
        print(f"     âœ… [{username}] í”„ë¡œíŒŒì¼ë§ ì™„ë£Œ!")
        return final_response.text
    except Exception as e:
        print(f"     âŒ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        if "429" in str(e):
             print("     â³ ìµœì¢… ë‹¨ê³„ ì¿¼í„° ì´ˆê³¼! 60ì´ˆ ëŒ€ê¸° í›„ ë§ˆì§€ë§‰ ì‹œë„...")
             await asyncio.sleep(60)
             try:
                 final_response = await asyncio.to_thread(model.generate_content, final_prompt)
                 return final_response.text
             except Exception as e2:
                 return f"ì¬ì‹œë„ ì‹¤íŒ¨: {e2}\n\n[ì¤‘ê°„ ë¶„ì„ ë°ì´í„°]\n{combined_notes}"
        return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\n\n[ì¤‘ê°„ ë¶„ì„ ë°ì´í„°]\n{combined_notes}"

async def run_analysis(target_user=None):
    if not config.GOOGLE_API_KEY:
        print("âŒ ì„¤ì • ì˜¤ë¥˜: GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    genai.configure(api_key=config.GOOGLE_API_KEY)

    if not os.path.exists(INPUT_FILE):
        print(f"âŒ ë°ì´í„° ì˜¤ë¥˜: ì „ì²˜ë¦¬ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤ ({INPUT_FILE})")
        return

    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        data = json.load(f)

    targets = {}
    if target_user and target_user != "ALL":
        if target_user in data:
            targets[target_user] = data[target_user]
        else:
            print(f"âŒ ì‚¬ìš©ì '{target_user}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
    else:
        targets = data

    print(f"ğŸ§  AI í”„ë¡œíŒŒì¼ëŸ¬ ê°€ë™ (ëŒ€ìƒ: {len(targets)}ëª…)")
    print(f"   - ë¶„ì„ ëª¨ë¸: {config.GEMINI_MODEL}")
    print(f"   - ìµœì í™”: ëŒ€ìš©ëŸ‰ ì²­í¬ ì²˜ë¦¬ (ìš”ì²­ ìˆ˜ ìµœì†Œí™”)")
    
    for i, (user, user_data) in enumerate(targets.items()):
        print(f"\n[{i+1}/{len(targets)}] ========================================")
        
        analysis_result = await analyze_user(user, user_data)
        reporter.save_report(user, analysis_result)
        
        # ìœ ì € ê°„ ì¿¨íƒ€ì„ì„ ëŒ€í­ ëŠ˜ë¦¼ (ì—°ì† ìš”ì²­ìœ¼ë¡œ ì¸í•œ 429 ë°©ì§€)
        if i < len(targets) - 1:
            print("     ğŸ’¤ API ì•ˆì „ ì¿¨íƒ€ì„ (10ì´ˆ)...")
            await asyncio.sleep(10)

    print("\nâœ¨ ëª¨ë“  í”„ë¡œíŒŒì¼ë§ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")